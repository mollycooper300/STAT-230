---
title: 'STAT 231: Problem Set 7A'
author: "Molly Cooper"
date: "due by 5 PM on Monday, October 26"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

In order to most effectively digest the textbook chapter readings -- and the  new R commands each presents -- series A homework assignments are designed to encourage you to read the textbook chapters actively and in line with the textbook's Prop Tip of page 33:

"\textbf{Pro Tip}: If you want to learn how to use a particular command, we highly recommend running the example code on your own" 

A more thorough reading and light practice of the textbook chapter prior to class allows us to dive quicker and deeper into the topics and commands during class.  Furthermore, learning a programming lanugage is like learning any other language -- practice, practice, practice is the key to fluency.  By having two assignments each week, I hope to encourage practice throughout the week.  A little coding each day will take you a long way!

*Series A assignments are intended to be completed individually.*  While most of our work in this class will be collaborative, it is important each individual completes the active readings.  The problems should be straightforward based on the textbook readings, but if you have any questions, feel free to ask me!

Steps to proceed:

\begin{enumerate}
\item In RStudio, go to File > Open Project, navigate to the folder with the course-content repo, select the course-content project (course-content.Rproj), and click "Open" 
\item Pull the course-content repo (e.g. using the blue-ish down arrow in the Git tab in upper right window)
\item Copy ps7A.Rmd from the course repo to your repo (see page 6 of the GitHub Classroom Guide for Stat231 if needed)
\item Close the course-content repo project in RStudio
\item Open YOUR repo project in RStudio
\item In the ps7A.Rmd file in YOUR repo, replace "YOUR NAME HERE" with your name
\item Add in your responses, committing and pushing to YOUR repo in appropriate places along the way
\item Run "Knit PDF" 
\item Upload the pdf to Gradescope.  Don't forget to select which of your pages are associated with each problem.  \textit{You will not get credit for work on unassigned pages (e.g., if you only selected the first page but your solution spans two pages, you would lose points for any part on the second page that the grader can't see).} 
\end{enumerate}

```{r, setup, include=FALSE}
library(tidyverse)

knitr::opts_chunk$set(
  tidy=FALSE,     # display code as typed
  size="small")   # slightly smaller font for code
```


\newpage
# 1.  "Tell the truth. Don't steal. Don't harm innocent people."

In the textbook, the authors state, "Common sense is a good starting point for evaluating the ethics of a situation.  Tell the truth.  Don't steal.  Don't harm innocent people.  But, professional ethics also require a neutral, unemotional, and informed assessment."

(1a) Assuming the numbers reported in Figure 6.1 are correct (truthful), do you think Figure 6.1 is an *unethical* representation of the data presented?  Why or why not?

> ANSWER: I think that Figure 6.1 does certainly represent accurate numbers, however I do not believe it is an ethical representation of the story at hand. Any conventional graph is given with the scales increasing, while there is no rule (I know of) saying that you can't have the numbers on the y-axis in descending order, it is clearly a misdirecting design to promote a political agenda. When anyone looks at this graph they will intuitivly assume that gun violence has decreased since "Stand Your Ground" was ennacted, however the real correlation is completely opposite. This graph is meant to catch unassuming viewers and lead them to believe that a political agenda had a positive influence which it did not and is a maniupulative representation. I think that when it comes to data, the figures should be laid out in an easily digestible fashion and the viewer should have room to interpret it as they please. 

(1b) Pulling from the examples in the textbook, provide one example of a more nuanced ethical situation (one that you perhaps found surprising or hadn't considered before).

> ANSWER: I think Figure 6.2 is a great example of a more nuanced approach to misleading viewers through graph maniuplation. While I have considered/seen this example of unethical data maniuplation before, it was suprising to reflect on how often I've recently seen this technique used in politics today -- it's such a simple manipulation that I would have assumed it more difficult to fool people with an innapropriately sized scale, however I'm now considering how effective this probably is. Especially with this method of manipulation, viewers may have a more difficult time finding fault/combatting this graph because there is nothing as evidently strange about it and once the viewer realizes the skew it's more difficult to prove as unethical because technically that is a fairly common scale for degree farenheit and there is nothing else alarmingly strange about the visual. 

\newpage
# 2. Does publishing a flawed analysis raise ethical questions? 

In the course so far, we've touched upon some of the ethical considerations discussed in this chapter, including ethical acquisition of data (e.g., abiding by the scraping rules of a given website) and reproducibility.  At the end of Section 6.3.4 (the "Reproducible spreadsheet analysis" example), the authors ask: Does publishing a flawed analysis raise ethical questions?

After reading Section 6.4.1 ("Applying the precepts") for the "Reproducible spreadsheet analysis" example, re-consider that question: Does publishing a flawed analysis raise ethical questions?  And, a follow-up question for consideration: Does it depend on who published the flawed analysis (e.g., a trained data scientist? an economist who conducts data science work?  a psychologist who works with data? a clinician who dabbles in data science?)

In 4-6 sentences, respond to those questions and explain your response.   

> ANSWER: 

> (1) Does publishing a flawed analysis raise ethical questions?
After reading Section 6.4 I certainly do not believe anything different from before which is that: publishing flawed or skewed analysis is almost always an unethical approach to data analysis. The whole purpose of providing quantitative evidence and doing data analysis is to present unbiased information that may or may not pursuade the reader but at least give them some objective insight. I think that specifically, the "Reproducable Spreadsheet Analysis" example is a very nuanced issue of proper data wrangling, however that does not mean it shouldn't be addressed, like in this situation when it has greater political impacts. This should always apply, but specifically when data analysis is going to have large social, political, public, etc... impacts - there should be stringent measures taken to ensure data is found, analysed, and displayed in the most unbiased way possible, otherwise there is certainly a breach of ethics which could ultimately lead to great consequences. 

> (2) Does it depend on who published the flawed analysis?
The "Reproducable Spreadsheet Analysis" was certainly an interesting example of how ignorance or profession can be an innocent yet detrimental factor in analytical bias. While the skewed information may come from a good intention with a lack of understanding, it does not detract from the greater consequences which could ensue. Whether or not someone has a PhD in Data Science or just learned SQL, if they are being given the responsibility to find, intepret, and publish data (especially that has larger implications), there should be stringent policies which keep their methods in check and perhaps provide them with expert input, to ensure their end result is ethical. When it comes to data which provides high stakes evidence there can be no leniancy surrounding the background of a researcher, and it is ultimately unethical on the part of the institution which is conducting this research and the person who approves it -- if someone goes about it the wrong way based on their background. 


