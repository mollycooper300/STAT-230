---
title: "STAT 231: Problem Set 9B"
author: "Molly Cooper"
date: "due by 5 PM on Friday, November 13"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

This homework assignment is designed to help you further ingest, practice, and expand upon the material covered in class over the past week(s).  You are encouraged to work with other students, but all code and text must be written by you, and you must indicate below who you discussed the assignment with (if anyone).  

Steps to proceed:

\begin{enumerate}
\item In RStudio, go to File > Open Project, navigate to the folder with the course-content repo, select the course-content project (course-content.Rproj), and click "Open" 
\item Pull the course-content repo (e.g. using the blue-ish down arrow in the Git tab in upper right window)
\item Copy ps9B.Rmd from the course repo to your repo (see page 6 of the GitHub Classroom Guide for Stat231 if needed)
\item Close the course-content repo project in RStudio
\item Open YOUR repo project in RStudio
\item In the ps9B.Rmd file in YOUR repo, replace "YOUR NAME HERE" with your name
\item Add in your responses, committing and pushing to YOUR repo in appropriate places along the way
\item Run "Knit PDF" 
\item Upload the pdf to Gradescope.  Don't forget to select which of your pages are associated with each problem.  \textit{You will not get credit for work on unassigned pages (e.g., if you only selected the first page but your solution spans two pages, you would lose points for any part on the second page that the grader can't see).} 
\end{enumerate}

```{r, setup, include=FALSE}
library(tidyverse)
library(mdsr)
library(Lahman)
library(GGally)

knitr::opts_chunk$set(
  tidy=FALSE,     # display code as typed
  size="small")   # slightly smaller font for code
```


\newpage 
# If you discussed this assignment with any of your peers, please list who here:

> ANSWER: Alex Ristic

\newpage
# 1. MDSR Exercise 9.5

Baseball players are voted into the Hall of Fame by the members of the Baseball Writers of America Association.  Quantitative criteria are used by the voters, but they are also allowed wide discretion.  The following code identifies the position players who have been elected to the Hall of Fame and tabulates a few basic statistics, include their number of career hits (`tH`), home runs (`tHR`), runs batted in (`tRBI`), and stolen bases (`tSB`).  Use the `kmeans()` function to perform a cluster analysis on these players.  Describe the properties that seem common to each cluster.

> ANSWER:  Cluster 1: Has the highest correlation between career hits and all of the other metrics. 
>Cluster 2: Almost always has the most extreme low or high correlations, for example it has the lowest correlation between home runs and stolen bases but the highest between home runs and runs batted. 
>Cluster 3: Has an extremely high correlation between runs batted in and home runs and hits. 
It appears that overall the correlation coefficients are mainly what are determining the placement of position players into different clusters. Also, it appears that overall most clusers have very leftward skew in stolen bases. 

```{r}
##### PLEASE DO NOT CHANGE THIS SEED NUMBER
##### keep set.seed(75) 
set.seed(75)

hof <- Batting %>%
  group_by(playerID) %>%
  inner_join(HallOfFame, by = "playerID") %>%
  filter(inducted == "Y" & votedBy == "BBWAA") %>%
  summarize(tH = sum(H), tHR = sum(HR), tRBI = sum(RBI), tSB = sum(SB)) %>%
  filter(tH > 1000)

vars <- c("tH", "tHR", "tRBI", "tSB")

#Creating Figure to Observe Within-Cluster Variation
figure <- matrix(NA, nrow = 10, ncol = 2)
for(i in 1:10){
  figure[i, 1] <- i
  figure[i, 2] <- kmeans(hof[vars]
                         , centers = i
                         , nstart = 20)$tot.withinss
}

ggplot(data = as.data.frame(figure), aes(x = V1, y = V2)) +
  geom_point() +
  geom_line() +
  scale_x_continuous(breaks = c(1:10)) +
  labs(x = "K-Means", y = expression("Total W"[K-Means]))

#Applying K-Means Algorithm
km <- kmeans(hof[vars], centers = 3, nstart = 20)

#Creating Cluster Variable
cluster <- hof %>%
  mutate(cluster = as.character(km$cluster))

#Creating Matrix
ggpairs(data = cluster
        , aes(color = cluster)
        , columns = vars)

```


\newpage
# 2. MDSR Exercise 10.6 

\textit{Equal variance assumption}:  What is the impact of the violation of the equal variance assumption for linear regression models?  Repeatedly generate data from a "true" model given by the following code.  (Note that the standard deviation is dependent upon x2, which is random; i.e., the equal variance assumption is violated.  The Ys are *not* generated from a distribution with the same variance.)

For each simulation, fit the linear regression model and display the distribution of 1,000 estimates of the $\beta_1$ parameter.  Does the distribution of the estimates follow a normal distribution?

> ANSWER:   Yes, the distribution of the estimates appears to be an almost perfectly normal figure, thus the estimates follow a normal distribution despite these violations. 

```{r}
# number of observations in each sample
n_obs <- 250

# parameters held constant
rmse <- 1
beta0 <- -1
beta1 <- 0.5
beta2 <- 1.5

# how to generate data
x1 <- rep(c(0,1), each=n_obs/2)
x2 <- runif(n_obs, min=0, max=5)
y <- beta0 + beta1*x1 + beta2*x2 + rnorm(n=n_obs, mean=0, sd=rmse + x2)

# fit model
mod <- lm(y ~ x1 + x2)

# extract beta1 coefficient
summary(mod)$coeff["x1","Estimate"]

# now, write code to repeatedly generate data, fit the model, and extract the beta coefficient (1,000 times)

# number of simulations
n_sim <- 1000
betas <- rep(NA, n_sim)

# visualize sampling distribution for beta1 (e.g. with histogram or density plot)
for(i in 1:n_sim){
  x1 <- rep(c(0,1), each = n_obs/2)
  x2 <- runif(n_obs, min = 0, max = 5)
  y <- beta0 + beta1*x1 + beta2*x2 + rnorm(n = n_obs, mean = 0, sd = rmse + x2)
  mod <- lm(y ~ x1 + x2)
  betas[i] <- (summary(mod)$coeff)['x1' , 'Estimate']
}

betadata <- as.data.frame(betas)

#Creating a Visual
ggplot(data = betadata, aes(x = betas)) +
  geom_histogram(color = 'black', fill = 'grey') +
  labs(x = "Estimate of the Beta 1 Coefficient", x = "Number of Samples")

# suppose beta1_est is your results vector containing the beta1 estimates
ggplot(data = as.data.frame(betas), aes(sample = betas)) +
  stat_qq() + 
  stat_qq_line()
```



\newpage
# 3. MDSR Exercise 10.7

\textit{Skewed residuals}: What is the impact if the residuals from a linear regression model are skewed (and not from a normal distribution)?  Repeatedly generate data from a "true" model given by the parameters below.

For each simulation, fit the linear regression model and display the distribution of 1,000 estimates of the $\beta_1$ parameter.

> ANSWER:  It appears that no matter how many trials you run there appears to remain a completely normal distribution for the 1,000 estimates using the beta 1 parameter. Thus, there appears to be no particularly large impact from the skew. 

```{r}
# number of observations in each sample
n_obs <- 250

# parameters held constant
rmse <- 1
beta0 <- -1
beta1 <- 0.5
beta2 <- 1.5

# how to generate data
x1 <- rep(c(0,1), each=n_obs/2)
x2 <- runif(n_obs, min=0, max=5)
y <- beta0 + beta1*x1 + beta2*x2 + rexp(n=n_obs, rate=1/2)

#number of simulations
obs <- 1000
Beta1S <- rep(NA, obs)

#creating 1,000 estimates
for(i in 1: obs){
  x1 <- rep(c(0,1), each = n_obs/2)
  x2 <- runif(n_obs, min = 0, max = 5)
  y <- beta0 + beta1*x1 + beta2*x2 + rexp(n=n_obs, rate = 1/2)
  Mod <- lm(y ~ x1 + x2)
  Beta1S[i] <- (summary(Mod)$coeff)['x1', 'Estimate']
}

BetaData <- as.data.frame(Beta1S)

#Creating Distribution Visual
ggplot(data = BetaData, aes(x = Beta1S)) +
  geom_histogram(color = 'black', fill = 'grey') +
  labs(x = "Estimate of Beta 1 Coefficient", y = "Number of Samples")

# what does an exponential dist'n with rate = 1/2 look like? 
# very skewed!
rexp(n=10000, rate=1/2) %>%
  as.data.frame() %>%
  ggplot(aes(x=`.`)) +
    geom_histogram(color="black", fill="grey")

```


